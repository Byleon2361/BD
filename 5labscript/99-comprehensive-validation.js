// comprehensive-validation-sha256-fixed.js
db = db.getSiblingDB('news_aggregator');
print("Waiting 10 seconds for seed data to load...");
sleep(10000); // 10 —Å–µ–∫—É–Ω–¥ ‚Äî —Å –∑–∞–ø–∞—Å–æ–º
print("Starting validation...");

print('=== COMPREHENSIVE MONGODB NEWS AGGREGATOR VALIDATION ===');

let validationResults = {};

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ö–µ—à–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
function generateTitleHash(title) {
    // –ü—Ä–æ—Å—Ç–∞—è —Ö–µ—à-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    // –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ
    // –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    let hash = 0;
    const normalizedTitle = title.toLowerCase().trim();

    for (let i = 0; i < normalizedTitle.length; i++) {
        const char = normalizedTitle.charCodeAt(i);
        hash = ((hash << 5) - hash) + char;
        hash = hash & hash; // Convert to 32bit integer
    }

    return Math.abs(hash).toString(16).padStart(8, '0');
}

// –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ö–µ—à–µ–π
function checkExistingHashType() {
    const sampleDoc =
        db.news.findOne({titleHash : {$exists : true}}, {titleHash : 1});
    if (sampleDoc && sampleDoc.titleHash) {
        return {
            length : sampleDoc.titleHash.length,
            type : sampleDoc.titleHash.length === 32   ? 'MD5'
                   : sampleDoc.titleHash.length === 64 ? 'SHA256'
                                                       : 'Custom'
        };
    }
    return null;
}

// 1. –ü–†–û–í–ï–†–ö–ê –ë–ê–ó–û–í–´–• –°–¢–†–£–ö–¢–£–†
print('\n1. DATABASE STRUCTURE CHECK:');

// –ö–æ–ª–ª–µ–∫—Ü–∏–∏
const collections = db.getCollectionNames();
validationResults.collections = collections.length >= 3;
print('   Collections: ' + collections.join(', '));

// –î–æ–∫—É–º–µ–Ω—Ç—ã –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏—è—Ö
const newsCount = db.news.countDocuments();
const authorsStatsCount = db.authors_stats.countDocuments();
const categoriesCount = db.categories.countDocuments();
const commentsCount = db.comments.countDocuments();

validationResults.documentsCount =
    (newsCount + authorsStatsCount + categoriesCount + commentsCount) >= 500;
print('   News: ' + newsCount + ' documents');
print('   Authors Stats: ' + authorsStatsCount + ' documents');
print('   Categories: ' + categoriesCount + ' documents');
print('   Comments: ' + commentsCount + ' documents');
print('   TOTAL: ' +
      (newsCount + authorsStatsCount + categoriesCount + commentsCount) +
      ' documents');

// 2. –ü–†–û–í–ï–†–ö–ê –ò–ù–î–ï–ö–°–û–í
print('\n2. INDEXES CHECK:');

const newsIndexes = db.news.getIndexes();
validationResults.indexes = newsIndexes.length > 1;

print('   News indexes: ' + newsIndexes.length);
newsIndexes.forEach(idx => {
    print('     - ' + idx.name + ': ' + JSON.stringify(idx.key) +
          (idx.unique ? ' (unique)' : '') +
          (idx.expireAfterSeconds ? ' (TTL: ' + idx.expireAfterSeconds + 's)'
                                  : ''));
});

// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–µ–∫—Å—ã
const hasTextIndex = newsIndexes.some(idx => idx.textIndexVersion);
const hasUniqueIndex = newsIndexes.some(idx => idx.unique);
const hasTTLIndex = newsIndexes.some(idx => idx.expireAfterSeconds);
const hasArrayIndex =
    newsIndexes.some(idx => idx.key && idx.key["metadata.tags"]);
const hasPartialIndex = newsIndexes.some(idx => idx.partialFilterExpression);
validationResults.specialIndexes = hasTextIndex && hasUniqueIndex &&
                                   hasTTLIndex && hasArrayIndex &&
                                   hasPartialIndex;
print('   Text Index: ' + hasTextIndex);
print('   Unique Index: ' + hasUniqueIndex);
print('   TTL Index: ' + hasTTLIndex);
print('   Array Index: ' + hasArrayIndex);
print('   Partial Index: ' + hasPartialIndex);

// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ titleHash –∏–Ω–¥–µ–∫—Å–∞
const titleHashIndex = newsIndexes.find(idx => idx.key && idx.key.titleHash);
if (titleHashIndex) {
    print('   TitleHash Index: ' +
          (titleHashIndex.unique ? 'UNIQUE' : 'non-unique'));
    validationResults.titleHashIndex = titleHashIndex.unique;

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ö–µ—à–µ–π
    const hashInfo = checkExistingHashType();
    if (hashInfo) {
        print('   Existing hash length: ' + hashInfo.length + ' chars');
        print('   üîç Hash type: ' + hashInfo.type);

        // –ï—Å–ª–∏ —Ö–µ—à–∏ —É–∂–µ –µ—Å—Ç—å –∏ –æ–Ω–∏ 64 —Å–∏–º–≤–æ–ª–∞, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ SHA256 —Ä–∞–±–æ—Ç–∞–µ—Ç
        if (hashInfo.length === 64) {
            validationResults.existingSha256Hashes = true;
        }
    }
} else {
    print('   TitleHash Index: NOT FOUND');
    validationResults.titleHashIndex = false;
}

// 3. –ü–†–û–í–ï–†–ö–ê –ë–ê–ó–û–í–´–• –û–ü–ï–†–ê–¶–ò–ô
print('\n3. BASIC OPERATIONS CHECK:');

try {
    // INSERT —Å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–º —Ö–µ—à–µ–º
    const testTitle = "Validation Test Article " + Date.now();
    const testDoc = {
        title : testTitle,
        content : "Test content for validation",
        hash : "validation_test_" + Date.now(),
        titleHash : generateTitleHash(testTitle),
        category : "technology",
        author :
            {firstName : "Test", lastName : "User", email : "test@test.com"},
        metrics : {views : 0, likes : 0, shares : 0},
        metadata :
            {publishDate : new Date(), isActive : true, tags : [ "test" ]}
    };

    const insertResult = db.news.insertOne(testDoc);
    print('   insertOne: OK');
    print('   Generated hash: ' + testDoc.titleHash);

    // UPDATE —Å $set
    db.news.updateOne(
        {_id : insertResult.insertedId},
        {$set : {"metrics.views" : 100, "metadata.isFeatured" : true}});
    print('   updateOne with $set: OK');

    // UPDATE —Å $inc
    db.news.updateOne({_id : insertResult.insertedId},
                      {$inc : {"metrics.views" : 50}});
    print('   updateOne with $inc: OK');

    // UPDATE —Å $push
    db.news.updateOne({_id : insertResult.insertedId},
                      {$push : {"metadata.tags" : "validation"}});
    print('   updateOne with $push: OK');

    // SEARCH —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    const searchResults =
        db.news
            .find({
                $and : [
                    {category : {$in : [ "technology", "science" ]}},
                    {"metrics.views" : {$gt : 10}}
                ]
            })
            .limit(1)
            .count();
    print('   Search with $and/$in/$gt: OK');

    // PROJECTION
    const projected = db.news
                          .find({_id : insertResult.insertedId}, {
                              title : 1,
                              category : 1,
                              "metrics.views" : 1,
                              titleHash : 1,
                              _id : 0
                          })
                          .toArray();
    print('   Projection: OK');

    // DELETE
    db.news.deleteOne({_id : insertResult.insertedId});
    print('   deleteOne: OK');

    validationResults.basicOperations = true;
} catch (e) {
    validationResults.basicOperations = false;
    print('   Basic operations failed: ' + e.message);
}

// 4. –ü–†–û–í–ï–†–ö–ê AGGRECATION PIPELINES
print('\n4. AGGREGATION PIPELINES CHECK:');

try {
    // –ü—Ä–æ—Å—Ç–æ–π pipeline —Å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Å—Ç–∞–¥–∏—è–º–∏
    const pipeline1 = [
        {$match : {"metadata.isActive" : true}}, {$unwind : "$metadata.tags"},
        {$group : {_id : "$metadata.tags", count : {$sum : 1}}},
        {$project : {tag : "$_id", count : 1, _id : 0}}, {$sort : {count : -1}},
        {$limit : 5}
    ];

    const result1 = db.news.aggregate(pipeline1).toArray();
    print('   Basic pipeline with all required stages: ' + result1.length +
          ' results');

    // Pipeline —Å $lookup
    const pipeline2 = [
        { $match: { "metadata.isActive": true } },
        { $group: { 
            _id: "$author.email", 
            authorName: { $first: { $concat: ["$author.firstName", " ", "$author.lastName"] } },
            articlesCount: { $sum: 1 } 
        }},
        { $lookup: {
            from: "authors_stats",
            localField: "authorName", 
            foreignField: "authorName",
            as: "authorStats"
        }},
        { $unwind: { path: "$authorStats", preserveNullAndEmptyArrays: true } },
        { $project: { 
            authorName: 1, 
            articlesCount: 1,
            totalViews: "$authorStats.totalViews"
        }},
        { $sort: { articlesCount: -1 } },
        { $limit: 3 }
    ];

    const result2 = db.news.aggregate(pipeline2).toArray();
    print('   Pipeline with $lookup: ' + result2.length + ' results');

    validationResults.aggregations = result1.length > 0 && result2.length > 0;
} catch (e) {
    validationResults.aggregations = false;
    print('   Aggregations failed: ' + e.message);
}

// 5. –ü–†–û–í–ï–†–ö–ê –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò –ü–û TITLE HASH
print('\n5. TITLE DEDUPLICATION CHECK:');

try {
    if (!validationResults.titleHashIndex) {
        print('   ‚ùå UNIQUE INDEX titleHash NOT FOUND');
        print(
            '   Run: db.news.createIndex({ titleHash: 1 }, { unique: true, name: "uniq_title_hash" })');
        validationResults.deduplication = false;
    } else {
        print('   ‚úÖ UNIQUE INDEX titleHash: Found');

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ titleHash
        const existingTitleDuplicates =
            db.news
                .aggregate([
                    {$group : {_id : "$titleHash", count : {$sum : 1}}},
                    {$match : {count : {$gt : 1}}}, {$limit : 1}
                ])
                .toArray();

        if (existingTitleDuplicates.length > 0) {
            print('   ‚ö†Ô∏è  Found ' + existingTitleDuplicates.length +
                  ' existing title duplicate groups');
            validationResults.deduplication = false;
        } else {
            print('   ‚úÖ No existing title duplicates found');

            // –¢–ï–°–¢ –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò
            const testTitle = "Test Deduplication Article " + Date.now();
            const testTitleHash = generateTitleHash(testTitle);

            const testDoc1 = {
                title : testTitle,
                content : "Test content for deduplication",
                hash : "test_hash_" + Date.now(),
                titleHash : testTitleHash,
                category : "technology",
                author : {firstName : "Test", lastName : "User"},
                metadata : {publishDate : new Date()}
            };

            const testDoc2 = {
                title : testTitle, // –¢–æ—Ç –∂–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫!
                content : "Different content but same title",
                hash : "test_hash_" + (Date.now() + 1),
                titleHash : testTitleHash, // –¢–æ—Ç –∂–µ titleHash!
                category : "technology",
                author : {firstName : "Test", lastName : "User"},
                metadata : {publishDate : new Date()}
            };

            // –í—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            const firstInsert = db.news.insertOne(testDoc1);
            print('   ‚úÖ First document inserted successfully');

            // –ü—ã—Ç–∞–µ–º—Å—è –≤—Å—Ç–∞–≤–∏—Ç—å –≤—Ç–æ—Ä–æ–π –¥–æ–∫—É–º–µ–Ω—Ç —Å —Ç–µ–º –∂–µ titleHash
            try {
                db.news.insertOne(testDoc2);
                validationResults.deduplication = false;
                print(
                    '   ‚ùå Deduplication FAILED: Second document with same titleHash was inserted');
            } catch (e) {
                if (e.code === 11000) {
                    validationResults.deduplication = true;
                    print(
                        '   ‚úÖ Title-based deduplication WORKING: Second document correctly rejected');
                } else {
                    validationResults.deduplication = false;
                    print('   ‚ùå Unexpected error: ' + e.message);
                }
            }

            // –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            db.news.deleteOne({_id : firstInsert.insertedId});
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—è titleHash
        const docsWithoutTitleHash =
            db.news.countDocuments({titleHash : {$exists : false}});
        if (docsWithoutTitleHash > 0) {
            print('   ‚ö†Ô∏è  Found ' + docsWithoutTitleHash +
                  ' documents without titleHash field');
            print('   Run this script to fix:');
            print(`
            db.news.find({titleHash: {$exists: false}}).forEach(function(doc) {
                var newTitleHash = doc.title.toLowerCase().trim();
                // –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∞—Å—Ç–æ—è—â–∞—è SHA256 —Ñ—É–Ω–∫—Ü–∏—è
                db.news.updateOne(
                    {_id: doc._id},
                    {$set: {titleHash: newTitleHash}}
                );
            });
            `);
        } else {
            print('   ‚úÖ All documents have titleHash field');

            // –ï—Å–ª–∏ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–º–µ—é—Ç —Ö–µ—à–∏ –∏ –æ–Ω–∏ 64 —Å–∏–º–≤–æ–ª–∞, —Å—á–∏—Ç–∞–µ–º SHA256
            // –∞–∫—Ç–∏–≤–Ω—ã–º
            if (validationResults.existingSha256Hashes) {
                validationResults.sha256Active = true;
                print('   üîí SHA256-like hashes detected (64 chars)');
            }
        }
    }
} catch (e) {
    validationResults.deduplication = false;
    print('   ‚ùå Deduplication check failed: ' + e.message);
}

print('\n6. SPECIAL FEATURES CHECK:');

// –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
try {
    const textResults = db.news
                            .find({$text : {$search : "technology"}},
                                  {score : {$meta : "textScore"}})
                            .limit(1)
                            .toArray();
    validationResults.textSearch = textResults.length > 0;
    print('   Text search: ' +
          (textResults.length > 0 ? 'Working' : 'No results'));
} catch (e) {
    validationResults.textSearch = false;
    print('   Text search: ' + e.message);
}

// 7. –ü–†–û–í–ï–†–ö–ê –í–ò–¢–†–ò–ù–´ –î–ê–ù–ù–´–•
print('\n7. DATA MART CHECK:');

const dataMartExists = collections.includes('authors_daily_stats') ||
                       collections.includes('daily_stats');
if (dataMartExists) {
    const dataMartName = collections.includes('authors_daily_stats')
                             ? 'authors_daily_stats'
                             : 'daily_stats';
    const dataMartCount = db[dataMartName].countDocuments();
    validationResults.dataMart = dataMartCount > 0;
    print('   Data mart "' + dataMartName + '": ' + dataMartCount + ' records');

    // –ï—Å–ª–∏ –≤–∏—Ç—Ä–∏–Ω–∞ –ø—É—Å—Ç–∞—è, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –∑–∞–ø–æ–ª–Ω–∏—Ç—å
    if (dataMartCount === 0) {
        print('   üí° Run data-mart.js to populate the data mart');
    }
} else {
    validationResults.dataMart = false;
    print('   No data mart found');
}

// 8. –ü–†–û–í–ï–†–ö–ê EXPLAIN –ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò
print('\n8. PERFORMANCE CHECK:');

try {
    const explainResult =
        db.news.find({category : "technology"}).explain("executionStats");
    validationResults.explain = true;
    print('   Explain works: ' +
          explainResult.executionStats.executionTimeMillis + 'ms');
    print('   Documents examined: ' +
          explainResult.executionStats.totalDocsExamined);
} catch (e) {
    validationResults.explain = false;
    print('   Explain failed: ' + e.message);
}

// 9. –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê
print('\nVALIDATION SUMMARY:');
print('=====================');

const requirements = [
    {name : 'Database Structure', result : validationResults.collections},
    {name : '500+ Documents', result : validationResults.documentsCount},
    {name : 'Indexes Created', result : validationResults.indexes},
    {name : 'Special Indexes', result : validationResults.specialIndexes},
    {name : 'Basic Operations', result : validationResults.basicOperations},
    {name : 'Aggregation Pipelines', result : validationResults.aggregations}, {
        name : 'Deduplication by Title Hash',
        result : validationResults.deduplication
    },
    {name : 'Text Search', result : validationResults.textSearch},
    {name : 'Data Mart', result : validationResults.dataMart},
    {name : 'Performance Analysis', result : validationResults.explain}
];

let passed = 0;
requirements.forEach(req => {
    const status = req.result ? 'PASS' : 'FAIL';
    print('   ' + status + ' ' + req.name);
    if (req.result)
        passed++;
});

print('\nRESULTS: ' + passed + '/' + requirements.length +
      ' requirements passed');

if (passed === requirements.length) {
    print('\nüéâ ALL REQUIREMENTS COMPLETED SUCCESSFULLY!');
    print('=========================================');
    print('MongoDB News Aggregator is fully operational!');

    // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ SHA256
    if (validationResults.sha256Active) {
        print(
            'üîí SHA256-like hashing is active (64-character hashes detected)');
    }
} else {
    print('\n‚ö†Ô∏è  SOME REQUIREMENTS NEED ATTENTION');
    print('=================================');

    if (!validationResults.titleHashIndex) {
        print('\nüîß FIX REQUIRED:');
        print('   Run this command ONCE:');
        print(
            '   db.news.createIndex({ titleHash: 1 }, { unique: true, name: "uniq_title_hash" })');
    }

    if (!validationResults.deduplication && validationResults.titleHashIndex) {
        print('\nüîß FIX REQUIRED:');
        print('   Ensure all documents have titleHash field');
    }

    if (!validationResults.dataMart) {
        print('\nüîß FIX REQUIRED:');
        print('   Run data-mart.js to populate data mart');
    }

    print('\nCheck the failed items above and run the corresponding scripts.');
}

// 10. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –¢–ï–°–¢–´ REST API
print('\n9. REST API READINESS CHECK:');

const apiReadiness = {
    topNews : db.news.countDocuments({"metadata.isActive" : true}) > 0,
    categories : db.categories.countDocuments() > 0,
    authors : db.authors_stats.countDocuments() > 0,
    search : db.news.countDocuments({$text : {$search : "technology"}}) > 0,
    deduplication : validationResults.deduplication
};

print('   Top news endpoint: ' +
      (apiReadiness.topNews ? '‚úÖ Ready' : '‚ùå No data'));
print('   Categories endpoint: ' +
      (apiReadiness.categories ? '‚úÖ Ready' : '‚ùå No data'));
print('   Authors endpoint: ' +
      (apiReadiness.authors ? '‚úÖ Ready' : '‚ùå No data'));
print('   Search endpoint: ' +
      (apiReadiness.search ? '‚úÖ Ready' : '‚ùå No data'));
print('   Deduplication: ' +
      (apiReadiness.deduplication ? '‚úÖ Active' : '‚ùå Inactive'));

// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ö–µ—à–∞—Ö
const hashInfo = checkExistingHashType();
if (hashInfo) {
    print('   Hash type: ' + hashInfo.type + ' (' + hashInfo.length +
          ' chars)');
}

print('\n=== VALIDATION COMPLETED ===');